#plan_task.py
from .config import config, APIKeyNotFoundError
import instructor
from openai import OpenAI
from typing import List, Dict, Any
from pydantic import BaseModel, Field
from collections import deque
import time
from .models import *
from .search_for_single_series import find_relevant_series
from .single_series import ask_questions_about_series
from groq import Groq



try:
    client = instructor.from_openai(OpenAI(api_key=config.get_api_key("OPENAI_API_KEY")))
    groq_client = instructor.from_groq(Groq(api_key=config.get_api_key("GROQ_API_KEY")))
    FRED_API_KEY = config.get_api_key('FRED_API_KEY')
except APIKeyNotFoundError as e:
    print("API KEY Not Found!")
except Exception as e:
    print(e)


prompt = '''
You are an expert economist AI assistant specializing in the FRED (Federal Reserve Economic Data) database. Your task is to generate a Directed Acyclic Graph (DAG) of tasks to gather, analyze, and display data for answering user queries about economic topics.

Given a user query, your job is to:
1. Analyze the query to identify the main economic topics and indicators involved.
2. Generate a DAG of tasks, where each task is a node in the graph.
3. Use three types of nodes:
   a. SearchNode: for searching FRED series (query parameter required). the search node should be in natural language english, and not FRED specific terms. Add a few synonyms as well, as well as technical terms. 
   b. CodeNode: for writing analysis code (code parameter required, must depend on at least one SearchNode). No instructiong, nothing, just leave it as it is for now
   c. DisplayNode: for displaying results (display_type parameter required, must depend on atleast one CodeNode)

Each node should have:
   - A unique ID
   - A list of dependencies (IDs of other nodes it depends on)
   - A task description. In CodeNode, just give a natural language instruction of how to do the tasks using numpy, pandas only. there must be only one CodeNode. Do not give code in this, just give detailed instructions on what to do.
   - Specific parameters based on the node type

Ensure that:
1. The graph is acyclic (no circular dependencies)
2. Each task is specific and actionable
3. The overall graph, when executed, would provide a comprehensive answer to the user's query
4. Include a mix of search, code, and display nodes to fully address the query. There should be only one codeNode, after all the search has been done

Your output should be a list of DAG nodes, each with the appropriate structure based on its type.
'''


def topological_sort(dag: DAG) -> List[DAGNodeBase]:
    in_degree = {node.id: len(node.dependencies) for node in dag.nodes}
    nodes_by_id = {node.id: node for node in dag.nodes}
    queue = deque([node for node in dag.nodes if len(node.dependencies) == 0])
    result = []
    
    while queue:
        node = queue.popleft()
        result.append(node)
        for other_node in dag.nodes:
            if node.id in other_node.dependencies:
                in_degree[other_node.id] -= 1
                if in_degree[other_node.id] == 0:
                    queue.append(other_node)
    
    if len(result) != len(dag.nodes):
        raise ValueError("The graph contains a cycle")
    
    return result

def execute_dag(dag: DAG, query:int) -> DAGWithOutput:
    sorted_nodes = topological_sort(dag)
    node_outputs: Dict[str, Any] = {}
    output_nodes: List[DAGNodeWithOutput] = []
    
    for node in sorted_nodes:
        print(f"Executing node: {node.id}")
        inputs = {dep: node_outputs[dep] for dep in node.dependencies}
        
        if node.node_type == "SearchNode":
            search_node = SearchNode(**node.model_dump())
            relevant_series = find_relevant_series(query=search_node.query, verbose=True)
            node_outputs[node.id] = relevant_series
            output_node = SearchNodeWithOutput(**node.dict(), output=relevant_series)
        
        elif node.node_type == "CodeNode":
            all_series = [s for dep_output in inputs.values() for s in dep_output if isinstance(dep_output, list) and all(isinstance(item, SeriesForSearch) for item in dep_output)]
            print(all_series)

            result = ask_questions_about_series(series_list=all_series, query=query)
            node_outputs[node.id] = result
            output_node = CodeNodeWithOutput(**node.dict(), output=result)
        
        elif node.node_type == "DisplayNode":
            node_outputs[node.id] = None 
            #output_node = DisplayNodeWithOutput(**node.dict(), output=inputs)
        
        else:
            raise ValueError(f"Unknown node type: {node.node_type}")
        
        output_nodes.append(output_node)
        print(f"Node {node.id} output: {output_node.output}")

    return DAGWithOutput(nodes=output_nodes)

def makeDAG(query:str) -> DAG:
    return client.chat.completions.create(
        response_model=DAG,
        model="gpt-4o",
        messages=[
            {"role": "system", "content": prompt},
            {"role": "user", "content": f"The user query is: {query}"}
        ]
    )

def main():
    print("Ask your question")
    query = input()
    start = time.time()

    dag: DAG = client.chat.completions.create(
        response_model=DAG,
        model="gpt-4o",
        messages=[
            {"role": "system", "content": prompt},
            {"role": "user", "content": f"The user query is: {query}"}
        ]
    )

    print("DAG structure:")
    print(dag)

    print("\nExecuting DAG:")
    dag_with_output = execute_dag(dag=dag, query=query)

    print("\nDAG with outputs:")
    #print(dag_with_output)

    print(f"\n\n\n. The time taken is {time.time() - start} seconds")

if __name__ == "__main__":
    main()# single_series.py
import os
import requests
import pandas as pd
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from .config import config, APIKeyNotFoundError
from .database_ops import get_units, check_series_exists
from .utils import store_series_in_DB
from openai import OpenAI
from groq import Groq
import subprocess
import time
from .models import SeriesForSearch, InstructionsList, CodeBlock
from .search_for_single_series import find_relevant_series 
import re
import instructor



try:
    FRED_API_KEY = config.get_api_key('FRED_API_KEY')
    OPENAI_API_KEY = config.get_api_key("OPENAI_API_KEY")
    openai_client = OpenAI(api_key=OPENAI_API_KEY)
    client = Groq(api_key=os.getenv("GROQ_API_KEY"))
    instructor_client = instructor.from_openai(OpenAI(api_key=OPENAI_API_KEY))
    groq_client = instructor.from_groq(Groq(api_key=config.get_api_key("GROQ_API_KEY")))
except APIKeyNotFoundError as e:
    raise e


def call_groq(messages: List[Dict[str, str]], model:str="llama3-70b-8192"):
    return client.chat.completions.create(messages=messages, model=model, temperature = 0.0)


def remove_all_extras(code:str):
    messages = [
        {
            "role": "system",
            "content": '''Your job is to remove EVERYTHING THAT IS NOT CODE. REMOVE EVERYTHING THAT IS NOT CODE. IF IT IS CODE IT STAYS. SOMETIMES THE CODE HAS THINGS LIKE "here is your code" or some other useless prefix. I need you to remove it. Just give me the code that is given to you. If only code is given to you, leave it untouched. Everything you put will be a python file. So don't output anything except code. '''
        },

        {
            "role": "user",
            "content": f"The input is {code}"
        }
    ]
    output = call_groq(messages, "llama3-8b-8192").choices[0].message.content
    return re.sub(r'^```|```$', '', output, flags=re.MULTILINE)
    

def fix_code(instructions:str, old_code:str, error:str) -> str:
    prompt =f''' The old code is {old_code}. The original instructions were {instructions}. The error in the old code is {error}. Write what is wrong with the code in the thoughts section, and then put code and code only in the code section. 
'''
    codeblock: CodeBlock = instructor_client.chat.completions.create(response_model=CodeBlock, messages=[
        {"role": "user", "content": prompt}
    ], model="gpt-4o")

    print(codeblock)

    code = (remove_all_extras(codeblock.code))
    print(code)
    return code

def load_series_observations(series_fred_id: str, output_file: str, verbose:bool = True) -> bool:
    url = f"https://api.stlouisfed.org/fred/series/observations?series_id={series_fred_id}&api_key={FRED_API_KEY}&file_type=json"
    response = requests.get(url)
    response.raise_for_status()

    ans = response.json()
    observations = ans['observations']
    observations_data = []

    for obs in observations:
        if 'date' in obs and 'value' in obs:
            try:
                if (obs['value']) != '.':
                    value = float(obs['value'])
                    observations_data.append({
                        'date': datetime.strptime(obs['date'], '%Y-%m-%d').date(),
                        'value': value
                    })
            except ValueError:
                print(f"Error converting value to float for {series_fred_id}: date = {obs['date']}, value = {obs['value']}")

    if verbose:
        print("got data for", series_fred_id)
        if observations_data:
            print(observations_data[0])
        else:
            print("No valid observations found")

    df = pd.DataFrame(observations_data)
    df.to_csv(output_file, index=False)
    print("saved csv", output_file)
    return True    
    
def run_code(file_name:str, code:str) -> Tuple[int, Optional[str]]:
    with open(file_name, 'w') as file:
        file.write(code)

    script_output = subprocess.run(["python3", file_name], capture_output=True, text=True)
    works = script_output.returncode == 0
    return (script_output.returncode, script_output.stdout if works else script_output.stderr)

        

def ask_questions_about_series(series_list: List[SeriesForSearch], query:str):
    try:
        output_file_list = []
        head_list = []
        for series in series_list:
            fred_id = series.fred_id
            series_exists = check_series_exists(fred_id)
            output_file = f"{fred_id}.csv" 
            if not series_exists:
                store_series_in_DB(series_fred_id=fred_id)
            else:
                print("series exists")
            string_to_append = f"Series name: {series.title}: csv_path:{output_file}. Units:{series.units}"
            output_file_list.append(string_to_append)
            units = get_units(fred_id=fred_id)
            if not units:
                raise ValueError("unable to get units")
            
            if not os.path.isfile(f"./{output_file}"):
                load_series_observations(series_fred_id=fred_id, output_file=output_file, verbose=True)

            df = pd.read_csv(output_file)
            head = f"{output_file}: " + str(df.head())
            head_list.append(head)

         
        prompt = f'''

Write me python code which answer's the user's question. Give as many details in the print statement as possible, all of these are going to be given to the highly-data curious user. The code should print that and that only. If you have more than one dataset think hard on which one would be more relevant and timely (higher frequency). Do not plot anything, do not graph anything. You have these CSV files csv file - {output_file_list}. It has the schema, {head_list}. The date is in YYYY-MM-DD format, and the data is in float.
'''
        instructions_prompt = f'''

You have these CSV files csv file - {output_file_list}. It has the schema, {head_list}. The date is in YYYY-MM-DD format, and the data is in float. Write me instructions to pass on to an AI agent to write code which answer's the user's question. Give as many details in the print statement as possible, all of these are going to be given to the highly-data curious user. The instructions to instruct the AI agent to print that and that only. If you have more than one dataset think hard on which one would be more relevant and timely (higher frequency). Do not plot anything, do not graph anything. Give highly detailed instructions in a setp by step format. You should print it in the format
1. Step 1
2. Step 2

These instructions should be very detailed and express to the AI code agent every step of what to do. The AI aigent should print one or two lines explaning the data and summarizing it. Print relevant details only, and do not print more than 5 lines at once. Do not ever print data out. Give an example of what to print so it is clear to the agent
'''
        print(instructions_prompt)
        
        instructions = groq_client.chat.completions.create(response_model=InstructionsList, model="llama3-70b-8192", messages=[
            {"role": "system", "content": instructions_prompt}, 
            {"role": "user", "content": f"the user query is {query}"}
        ])

        print(instructions)
        completion:CodeBlock = instructor_client.chat.completions.create(response_model=CodeBlock, messages=[
            {"role": "system", "content": prompt}, 
            {"role": "user", "content": f"The instructions are {str(instructions)}"}
        ], model="gpt-4o")

        print(completion)

        code = (remove_all_extras(completion.code))
        num_times = 1
        print("got code!")
        return_code, output =  run_code("LLMGenCode/test.py", code=code)
        while num_times <= 5:
            if return_code != 0:
                code = fix_code(instructions=instructions, old_code=code, error=output)
                run_code("LLMGenCode/test.py", code=code) 
                num_times+= 1
            else:
                return output
        
        raise Exception("Too many retries")

    except Exception as e:
        print(e)
        raise e
        return None



if __name__ == "__main__":
    firstTime = True
    print("What is your query?")
    query = input()
    start = time.time()
    print("started at", start)
    series_list: List[SeriesForSearch] = find_relevant_series(query=query, verbose=True)
    end_time = time.time()
    print("took", end_time-start, "time for this to happen")
    print(series_list)
    
    
    ask_questions_about_series(series_list, query)

# search_for_single_series.py
import chromadb
import os
from typing import List, Dict, Set
import instructor
from .config import config, APIKeyNotFoundError
from openai import OpenAI
from groq import Groq
from .models import SeriesForSearch, Keywords, ClassifiedSeries
from .database import Database, DatabaseConnectionError
os.environ['TOKENIZERS_PARALLELISM'] = 'false'

print("Imported libraries")

# Initialize Chroma client with persistent storage
chroma_persist_directory = os.path.join(os.path.dirname(__file__), "chroma_db")
chroma_client = chromadb.PersistentClient(path=chroma_persist_directory)
    
# Get the collection
collection = chroma_client.get_collection("fred-economic-series")
#tags_collection = chroma_client.get_collection("fred-tags")


try:
    FRED_API_KEY = config.get_api_key('FRED_API_KEY')
    OPENAI_API_KEY = config.get_api_key("OPENAI_API_KEY")
    openai_client = OpenAI(api_key=OPENAI_API_KEY)
    client = Groq(api_key=config.get_api_key("GROQ_API_KEY"))
    instructor_client = instructor.from_openai(OpenAI(api_key=OPENAI_API_KEY))
    instructor_groq_client = instructor.from_groq(Groq(api_key=config.get_api_key("GROQ_API_KEY")))
except APIKeyNotFoundError as e:
    raise e



def extract_keyword(user_query: str) -> Keywords:
    return instructor_client.chat.completions.create(
        model="gpt-4o-mini",
        response_model=Keywords,
        messages=[
            {"role": "system", "content": """
You are an expert in economic terminology and the FRED (Federal Reserve Economic Data) database. Your task is to convert user queries into the most appropriate search terms for the FRED database.
            """},
            {"role": "user", "content": f"""
Convert the following query into search terms for the FRED database:
"{user_query}"
Follow these rules strictly:
1. Provide only full terms as they would appear in the FRED database. For example, use "Gross Domestic Product" instead of "GDP".
2. Expand all common economic acronyms to their full forms.
3. Focus on specific economic indicators, measurements, or concepts.
4. Provide at most 3 key terms, prioritizing specificity and relevance to the FRED database. 
5. Do not include general words like "current", "rate" unless they are part of a specific economic term.
6. If the query mentions a specific country, include the full country name as part of the relevant economic term(s).
Respond with only the list of search terms, nothing else.
7. Be strict in your question. Ensure that the geographic region and all other data match what the user asked
            """}
        ]
    )

def keyword_semantic_search(keywords: List[str], n_results: int = 5, verbose:bool = False) -> Set[SeriesForSearch]:

    
    results = []
    ''' # TODO: Decide if this is needed or not
    for keyword in keywords:
        # Assuming collection.query is defined and functional
        keyword_results = collection.query(
            query_texts=[keyword],
            n_results=n_results
        )
        if verbose:
            print("the keyword is", keyword, "and the results are", keyword_results)
        results.append(keyword_results)
    '''
    
    query = ' '.join(keywords)

    keyword_results = collection.query(query_texts=[query], n_results=n_results)
    if verbose:
        print("the query is", query, "and the results are", keyword_results)
    results.append(keyword_results)


    series_set = set()
    
    for keyword_results in results:
        for i in range(len(keyword_results['ids'][0])):
            series = SeriesForSearch(
                fred_id=keyword_results['ids'][0][i],
                title=keyword_results['metadatas'][0][i]['title'],
                units=keyword_results['metadatas'][0][i]['units'],
                popularity=keyword_results['metadatas'][0][i]['popularity'],
                relevance_lower_better=keyword_results['distances'][0][i]
            )
            series_set.add(series)
    
    return series_set





def print_series_list(series_list:List[SeriesForSearch]) -> None:
    series_list = list(filter(lambda x: not x.relevance_lower_better or x.relevance_lower_better <= 1, series_list))
    series_list.sort(key=lambda x: x.relevance_lower_better)
    for series in series_list:
        print("id:", series.fred_id)
        print("title:", series.title)
        print("popularity:", series.popularity)
        print("units:", series.units)
        print("relevance:", series.relevance_lower_better)
        print("\n\n")
        print("------------------------")

def rank_relevant_outputs(series_list:List[SeriesForSearch], query:str) -> SeriesForSearch:
    instructor
    try:
    
        return instructor_groq_client.chat.completions.create(response_model=ClassifiedSeries, messages=[
            {"role": "system", "content": "You will be given a number of economic series from the user. Your job is to mark them as relevant or irrelevant for a given query and output it in the given format"}, {
                "role": "user", "content":f"The user's query is {query}. The possible datasets are {series_list}"
            }
        ], model="llama3-70b-8192")
    except Exception:
        return rank_relevant_outputs(series_list=series_list, query=query) 

def keyword_text_search(keywords: List[str]) -> List[SeriesForSearch]:
    results_set = set()
    cursor = Database.get_cursor()
    for keyword in keywords:
    # Use the LIKE command to search for each keyword separately
        cursor.execute("""
            SELECT fred_id, title, units, popularity
            FROM series
            WHERE title LIKE ?
        """, (f'%{keyword}%',))
        
        # Fetch all matching rows
        rows = cursor.fetchall()
        
        # Add each row to the results set to avoid duplicates
        for row in rows:
            results_set.add(SeriesForSearch(
                fred_id=row[0],
                title=row[1],
                units=row[2],
                popularity=row[3]
            ))

# Close the database connection
    
    
    # Return the results as a list
    return list(results_set)

def find_relevant_series(query:str, verbose:bool = False) -> List[SeriesForSearch]:
    keyword_list = extract_keyword(query)
    if verbose:
        print("Extracted keywords:", keyword_list.word)
    semantic_search_results = keyword_semantic_search(keyword_list.word, n_results=5)
    possible: ClassifiedSeries = rank_relevant_outputs(list(semantic_search_results), query=query)

    if verbose:
        print("the relevant series are", possible.relevant)
        print("\n\n")
        print("the not relevant series are", possible.notRelevant)
    return possible.relevant


if __name__ == "__main__":
    firstTime = True
    while True:
        if not firstTime:
            print("\n\n")
        print("What is your query?")
        query = input()
        print(f"\nQuery: {query}")
        find_relevant_series(query=query, verbose=True)
        firstTime = False# models.py
from pydantic import BaseModel, Field
from typing import Optional, List, Any, Union, Literal
from datetime import datetime, date
from enum import Enum

class Series(BaseModel):
    fred_id: str
    title: str
    observation_start: str
    observation_end: str
    frequency: str
    frequency_short: str
    units: str
    units_short: str
    seasonal_adjustment: str
    seasonal_adjustment_short: str
    last_updated: str
    popularity: int
    notes: Optional[str]

class DateValuePair(BaseModel):
    date: date
    value: float

class SeriesData(BaseModel):
    units: str
    ObservationsData: List[DateValuePair]

class SeriesForSearch(BaseModel):
    fred_id:str
    title:str
    units:str
    popularity: int
    relevance_lower_better: Optional[float]

    class Config:
        frozen = True

class SeriesForRanking(BaseModel):
    fred_id:str
    title:str
    units:str

class Keywords(BaseModel):
    word: List[str]

class ClassifiedSeries(BaseModel):
    relevant: List[SeriesForSearch]
    notRelevant: List[SeriesForSearch]

class Search(BaseModel):
    query: str

class SearchList(BaseModel):
    queries: List[Search]

class DAGNodeBase(BaseModel):
    id: str
    dependencies: List[str] = Field(default_factory=list)
    node_type: Literal["search", "code", "display"]
    task: str

class DAGNodeWithOutput(DAGNodeBase):
    output: Optional[Any] = None

class SearchNode(DAGNodeBase):
    node_type: str = "SearchNode"
    query: str

class SearchNodeWithOutput(SearchNode, DAGNodeWithOutput):
    pass

class CodeNode(DAGNodeBase):
    node_type: str = "CodeNode"
    

class CodeNodeWithOutput(CodeNode, DAGNodeWithOutput):
    pass

class DisplayNode(DAGNodeBase):
    node_type: str = "DisplayNode"
    display_type: str


class DisplayNodeWithOutput(DisplayNode, DAGNodeWithOutput):
    pass


NodeType = Union[SearchNode, CodeNode, DisplayNode]

class DAG(BaseModel):
    nodes: List[NodeType]


class DAGWithOutput(BaseModel):
    nodes: List[DAGNodeWithOutput]

class InstructionsList(BaseModel):
    instructions: List[str]

class CodeBlock(BaseModel):
    thoughts: str
    code: str